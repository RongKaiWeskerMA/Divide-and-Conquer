{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3,10,2, stride = 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = lambda x: x.view(-1)\n",
    "        self.fc1 = nn.Linear(160,5)\n",
    "        self.seq = nn.Sequential(nn.Linear(5,3), nn.Linear(3,2))\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv(x))\n",
    "        x = self.fc1(self.flatten(x))\n",
    "        x = self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = myNet()\n",
    "visualisation = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_fn(m, i, o):\n",
    "    visualisation[m] = o "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_layers(net):\n",
    "    for name, layer in net._modules.items():\n",
    "    #If it is a sequential, don't register a hook on it\n",
    "    # but recursively register hook on all it's module children\n",
    "        if isinstance(layer, nn.Sequential):\n",
    "            get_all_layers(layer)\n",
    "        else:\n",
    "    # it's a non sequential. Register a hook\n",
    "            layer.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([tensor([[[[-0.4049,  0.4184, -0.1858, -0.8478],\n",
       "          [-0.2995,  0.4221,  0.5647,  0.2976],\n",
       "          [-0.9562,  0.1984,  0.2744,  0.3994],\n",
       "          [ 0.3209, -0.0563,  0.7810,  0.3795]],\n",
       "\n",
       "         [[ 1.4633, -0.0306,  0.4014,  0.5048],\n",
       "          [-0.6668, -0.2590,  0.3717,  0.6039],\n",
       "          [ 0.3009, -0.0036, -0.6575,  0.0809],\n",
       "          [-0.0768, -0.3139,  0.5822, -0.4153]],\n",
       "\n",
       "         [[ 0.2116,  0.2943,  0.9865,  0.4202],\n",
       "          [-0.0887, -1.0359,  0.5368,  0.3085],\n",
       "          [ 0.3922, -0.0531,  1.2123,  0.6603],\n",
       "          [-0.5003,  0.3095,  0.4923,  0.8078]],\n",
       "\n",
       "         [[-0.1239, -0.3719,  0.2554,  0.4199],\n",
       "          [ 1.1408,  0.6771, -0.1203, -0.4970],\n",
       "          [ 0.3229,  0.4072,  0.3754, -0.3250],\n",
       "          [ 0.2893,  0.9996, -0.1025,  0.7830]],\n",
       "\n",
       "         [[ 0.6095, -0.8132,  0.4247, -0.6393],\n",
       "          [ 0.3060,  1.4200,  0.1869,  0.4822],\n",
       "          [-0.4590,  0.3961, -0.4835, -0.1663],\n",
       "          [ 1.0239,  0.0932,  1.3263,  0.4975]],\n",
       "\n",
       "         [[-0.1285, -0.3250,  0.4392, -1.0376],\n",
       "          [ 0.9683, -0.2572, -0.5793,  0.0072],\n",
       "          [ 0.5286,  0.6181,  0.4924, -0.0585],\n",
       "          [-0.0640,  0.2690, -0.5349,  0.2948]],\n",
       "\n",
       "         [[-0.3420,  0.8384, -0.0221,  0.1908],\n",
       "          [-0.8163, -0.9547, -0.1639,  0.2351],\n",
       "          [-0.2896,  0.3171,  0.1456,  0.1528],\n",
       "          [-0.0309, -1.4231, -0.9695, -0.5938]],\n",
       "\n",
       "         [[ 0.4225,  0.4241,  0.7099, -0.2111],\n",
       "          [ 0.2355, -1.6337, -0.5707,  0.3577],\n",
       "          [ 0.3888,  0.2774,  0.0049,  0.3062],\n",
       "          [-0.6979, -0.5100, -1.1924, -0.9330]],\n",
       "\n",
       "         [[ 0.4518,  0.2978,  1.1289,  0.4291],\n",
       "          [ 0.7337,  0.3108, -0.5335,  0.3434],\n",
       "          [-0.1848,  0.3573,  0.0895,  0.8401],\n",
       "          [-0.4385,  0.4818, -0.3773,  0.3847]],\n",
       "\n",
       "         [[-0.5915, -0.7772,  0.7590, -0.0192],\n",
       "          [ 0.3068, -0.0900, -0.3417, -0.0520],\n",
       "          [-0.5900, -0.5155,  0.0621, -0.3227],\n",
       "          [ 0.3533, -0.2741,  0.3178,  0.4294]]]],\n",
       "       grad_fn=<ConvolutionBackward0>), tensor([[[[0.0000, 0.4184, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4221, 0.5647, 0.2976],\n",
       "          [0.0000, 0.1984, 0.2744, 0.3994],\n",
       "          [0.3209, 0.0000, 0.7810, 0.3795]],\n",
       "\n",
       "         [[1.4633, 0.0000, 0.4014, 0.5048],\n",
       "          [0.0000, 0.0000, 0.3717, 0.6039],\n",
       "          [0.3009, 0.0000, 0.0000, 0.0809],\n",
       "          [0.0000, 0.0000, 0.5822, 0.0000]],\n",
       "\n",
       "         [[0.2116, 0.2943, 0.9865, 0.4202],\n",
       "          [0.0000, 0.0000, 0.5368, 0.3085],\n",
       "          [0.3922, 0.0000, 1.2123, 0.6603],\n",
       "          [0.0000, 0.3095, 0.4923, 0.8078]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.2554, 0.4199],\n",
       "          [1.1408, 0.6771, 0.0000, 0.0000],\n",
       "          [0.3229, 0.4072, 0.3754, 0.0000],\n",
       "          [0.2893, 0.9996, 0.0000, 0.7830]],\n",
       "\n",
       "         [[0.6095, 0.0000, 0.4247, 0.0000],\n",
       "          [0.3060, 1.4200, 0.1869, 0.4822],\n",
       "          [0.0000, 0.3961, 0.0000, 0.0000],\n",
       "          [1.0239, 0.0932, 1.3263, 0.4975]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.4392, 0.0000],\n",
       "          [0.9683, 0.0000, 0.0000, 0.0072],\n",
       "          [0.5286, 0.6181, 0.4924, 0.0000],\n",
       "          [0.0000, 0.2690, 0.0000, 0.2948]],\n",
       "\n",
       "         [[0.0000, 0.8384, 0.0000, 0.1908],\n",
       "          [0.0000, 0.0000, 0.0000, 0.2351],\n",
       "          [0.0000, 0.3171, 0.1456, 0.1528],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.4225, 0.4241, 0.7099, 0.0000],\n",
       "          [0.2355, 0.0000, 0.0000, 0.3577],\n",
       "          [0.3888, 0.2774, 0.0049, 0.3062],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.4518, 0.2978, 1.1289, 0.4291],\n",
       "          [0.7337, 0.3108, 0.0000, 0.3434],\n",
       "          [0.0000, 0.3573, 0.0895, 0.8401],\n",
       "          [0.0000, 0.4818, 0.0000, 0.3847]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.7590, 0.0000],\n",
       "          [0.3068, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0621, 0.0000],\n",
       "          [0.3533, 0.0000, 0.3178, 0.4294]]]], grad_fn=<ReluBackward0>), tensor([ 0.1054,  0.1930,  0.0669, -0.0613,  0.2940], grad_fn=<AddBackward0>), tensor([-0.1591, -0.0368,  0.4008], grad_fn=<AddBackward0>), tensor([-0.3033, -0.4063], grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_layers(net)\n",
    "out = net(torch.randn(1,3,8,8))\n",
    "visualisation.values() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k-plane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
